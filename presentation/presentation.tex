\documentclass{beamer}
\usepackage[utf8]{inputenc}
%\usepackage{style}
\usetheme{Warsaw}
\usepackage{amsmath}
\usepackage{graphicx, import, pdfpages, listings, tikz}
\title 
{Dependency parsing using neural networks.}
\author % (optional, for multiple authors)
{Michał Zapotoczny\\ promotor: dr Jan Chorowski}
\institute 
{
  Instytut Informatyki\\Uniwersytet Wrocławski
}
\date
{19.09.2017}

\begin{document}

\frame{\titlepage}

\begin{frame}
    \frametitle{What is dependency parsing and why it matters?}
    \begin{definition}In dependency parsing we create a tree having words as nodes,
    representing structure of the sentence\end{definition}
    \begin{center}
      \resizebox{0.8\textwidth}{!}{
        \import{img/dep/}{dep.pdf_tex}
      }\\
    \begin{itemize}
        \item Each word is connected to another word (or special ROOT token) via a labelled arc, forming a directed tree.
        \item Head-Dependent replationship is good approximation to semantic relationship between words
        \item Is used as part of NLP pipeline for many tasks (named entity recognition, relation extraction etc.)
    \end{itemize}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Data}
    \begin{itemize}
        \item We train our network with supervised learning, so we need lare amount of
            parsing examples
        \item Universal Dependencies is a large dataset of dependency parse trees for
            many languages (version 2.0 contains 70 treebanks for 50 languages).
            All treebanks in UD uses unified format
    \end{itemize}
\end{frame}
\begin{frame}
    \frametitle{Metric}
    \begin{itemize}
        \item UAS - How many words have right parent?
        \item LAS - How many words have right parent and arc label?
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Network architecture}
    \begin{center}
        \resizebox{\textwidth}{!}{
          \import{img/network/}{network.pdf_tex}
        }
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Results}
    {\scriptsize
    \begin{table}[!htbp]
      \centering
      \begin{tabular}{l l | l l | l l | l l}
          language & \#sentences & \multicolumn{2}{c|}{Ours} & \multicolumn{2}{c|}{SyntaxNet[2016]} & \multicolumn{2}{c}{ParseySaurus[2017]} \\ \hline
        & & UAS & LAS & UAS & LAS & UAS & LAS\\ \hline
        Czech & 87 913 & \textbf{91.41} & \textbf{88.18} & 89.47 & 85.93 & 89.09 & 84.99 \\
        Polish & 8 227 & 90.26 & 85.32 & 88.30 & 82.71 & \textbf{91.86} & \textbf{87.49}\\
        Russian & 5 030 & 83.29 & 79.22 & 81.75 & 77.71 & \textbf{84.27} & \textbf{80.65} \\
        German & 15 892 & 82.67 & 76.51 & 79.73 & 74.07 & \textbf{84.12} & \textbf{79.05}\\
        English & 16 622 & 87.44 & 83.94 & 84.79 & 80.38 & \textbf{87.86} & \textbf{84.45}\\ 
        French & 16 448 & \textbf{87.25} & \textbf{83.50} & 84.68 & 81.05 & 86.61 & 83.1\\
        Ancient Greek & 25 251 & \textbf{78.96} & \textbf{72.36} & 68.98 & 62.07 & 73.85 & 68.1
      \end{tabular}
      \caption{Baseline results of models trained on single languages from
        UD v1.3. Our models use only the orthographic representation of
        tokenized words during inference and works without a separate POS tagger.}
      \label{tab:universal}
    \end{table}
    }
\end{frame}

\begin{frame}
    \frametitle{Multilingual training}
    \begin{itemize}
        \item Polish language has small number of dependency parsing examples (8 227 sentences, 83 571 words)
        \item Czech language has much better dataset (77 765 sentences, 1 332 566 words)
        \item Polish and Czech are similar.
        \item Use multitask learning to learn both languages at the same time
        \item How? Have 2 copies of the network and share part of the parameters between them
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Multilingual results}
    {\scriptsize
    \begin{table}[!htbp]
      \centering  
      \begin{tabular}{l | l l c c}
        Shared parts & Main lang & Aux lang & UAS & LAS \\ \hline
          - & Polish & - & 90.31 & 85.21 \\
        \emph{Parser} & Polish & Czech & 90.72 & 85.57 \\ % local_storage/multi/pl_cs_merge_generator
        \emph{Tagger, Parser} & Polish & Czech & 91.19 & 86.37 \\ % sonata2:  /pio/lscratch/1/i248100/pl_cs_unification_exclude_pos
        \emph{Tagger, POS Predictor, Parser} & Polish & Czech & 91.65 & 86.88 \\ % local_storage/dependency_pl_cs_new
        \emph{Reader, Tagger, POS Predictor, Parser} & Polish & Czech & \textbf{91.91} & \textbf{87.77} \\\hline % sonata1: /pio/lscratch/1/i248100/multi_pl_cs_different_eos_merge_all
        \emph{Parser} & Polish & Russian & 90.31 & 85.07 \\  % local_storage2/pl-ru-inc-generator
        \emph{Tagger, POS Predictor, Parser} & Polish & Russian &
        \textbf{91.34} & \textbf{86.36} \\ 
        \emph{Reader, Tagger, POS Predictor, Parser} & Polish & Russian & 89.16 & 82.94 \\  %  local_storage2/multi_pl_ru_different_eos_merge_all
    \hline\hline % local_storage/multi/pl_ru_same_eos
        - & Russian & - & 83.43 & 79.24 \\
        \emph{Parser} & Russian & Czech & 83.15 & 78.69 \\  % sonata0: /pio/lscratch/1/i248100/ru-cs-parser
        \emph{Tagger, POS Predictor, Parser} & Russian & Czech & 83.91 & 79.79 \\ %  local_storage/multi/ru_cs
        \emph{Reader, Tagger, POS Predictor, Parser} & Russian & Czech & \textbf{84.78} & \textbf{80.35} % sonata1:  /pio/lscratch/1/i248100/ru-cs-all
      \end{tabular}
      \label{tab:multi_baseline}
      \caption{Impact of parameter sharing strategies on main language parsing accuracy when multilingual training
        is used for additional supervision.}
    \end{table}
    }
\end{frame}
%\input{end.tex}

\begin{frame}
    \frametitle{Thank you}
    \begin{center}
        {\Huge Questions?}
    \end{center}
\end{frame}

\end{document}
